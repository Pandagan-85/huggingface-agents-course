{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1b00e1-a676-46a9-b1d8-bdfdc8dda1a2",
   "metadata": {},
   "source": [
    "# What is LangGraph?\n",
    "\n",
    "LangGraph is a framework developed by LangChain to manage the control flow of applications that integrate an LLM.\n",
    "\n",
    "## Is LangGraph different from LangChain ?\n",
    "LangChain provides a standard interface to interact with models and other components, useful for retrieval, LLM calls and tools calls. The classes from LangChain might be used in LangGraph, but do not HAVE to be used.\n",
    "\n",
    "The packages are different and can be used in isolation, but, in the end, all resources you will find online use both packages hand in hand.\n",
    "\n",
    "## When should I use LangGraph ?\n",
    "### Control vs freedom\n",
    "When designing AI applications, you face a fundamental trade-off between control and freedom:\n",
    "\n",
    "- **Freedom** gives your LLM more room to be creative and tackle unexpected problems.\n",
    "- **Control** allows you to ensure predictable behavior and maintain guardrails.\n",
    "  \n",
    "Code Agents, like the ones you can encounter in smolagents, are very free. They can call multiple tools in a single action step, create their own tools, etc. However, this behavior can make them less predictable and less controllable than a regular Agent working with JSON!\n",
    "\n",
    "`LangGraph` is on the other end of the spectrum, it shines when you need **“Control” on the execution of your agent**.\n",
    "\n",
    "LangGraph is particularly valuable when you need **Control over your applications**. It gives you the tools to build an application that follows a predictable process while still leveraging the power of LLMs.\n",
    "\n",
    "Put simply, if your application involves a series of steps that need to be orchestrated in a specific way, with decisions being made at each junction point, **LangGraph provides the structure you need**.\n",
    "\n",
    "As an example, let’s say we want to build an LLM assistant that can answer some questions over some documents.\n",
    "\n",
    "Since LLMs understand text the best, before being able to answer the question, you will need to convert other complex modalities (charts, tables) into text. However, that choice depends on the type of document you have!\n",
    "\n",
    "This is a branching that I chose to represent as follow :\n",
    "\n",
    "![](../../image/flow_langgraph.png)\n",
    "\n",
    "\n",
    "While this branching is deterministic, you can also design branching that are conditioned on the output of an LLM making them undeterministic.\n",
    "\n",
    "The key scenarios where LangGraph excels include:\n",
    "\n",
    "- **Multi-step reasoning processes** that need explicit control on the flow\n",
    "- **Applications requiring persistence of state** between steps\n",
    "- **Systems that combine deterministic logic with AI capabilities**\n",
    "- **Workflows that need human-in-the-loop interventions**\n",
    "- **Complex agent architectures** with multiple components working together\n",
    "\n",
    "In essence, whenever possible, **as a human**, design a flow of actions based on the output of each action, and decide what to execute next accordingly. In this case, LangGraph is the correct framework for you!\n",
    "\n",
    "LangGraph is, in my opinion, the most production-ready agent framework on the market.\n",
    "\n",
    "## How does LangGraph work?\n",
    "\n",
    "At its core, `LangGraph` uses a directed graph structure to define the flow of your application:\n",
    "\n",
    "- **Nodes** represent individual processing steps (like calling an LLM, using a tool, or making a decision).\n",
    "- **Edges** define the possible transitions between steps.\n",
    "- **State** is user defined and maintained and passed between nodes during execution. When deciding which node to target next, this is the current state that we look at.\n",
    "\n",
    "## How is it different from regular python? Why do I need LangGraph?\n",
    "While technically true, LangGraph offers some advantages over vanilla Python for building complex systems. You could build the same application without LangGraph, but it builds easier tools and abstractions for you.\n",
    "\n",
    "It includes states, visualization, logging (traces), built-in human-in-the-loop, and more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd778a9-73cc-4aaa-9def-49522373653b",
   "metadata": {},
   "source": [
    "## Building Blocks of LangGraph\n",
    "To build applications with LangGraph, you need to understand its core components. Let’s explore the fundamental building blocks that make up a LangGraph application.\n",
    "\n",
    "\n",
    "An application in LangGraph starts from an entrypoint, and depending on the execution, the flow may go to one function or another until it reaches the END.\n",
    "\n",
    "![](../../image/application.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6be12-240b-4cca-ae52-1d2661097b6a",
   "metadata": {},
   "source": [
    "### 1. State\n",
    "State is the central concept in LangGraph. It represents all the information that flows through your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7475c3c-2728-4d85-ac2d-7d4436e70ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfedcfc7-0747-4564-958a-ff3900a533de",
   "metadata": {},
   "source": [
    "The state is **User defined**, hence the fields should carefully be crafted to contain all data needed for decision-making process!\n",
    "\n",
    "> 💡 Tip: Think carefully about what information your application needs to track between steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70959712-c22b-4e62-ae63-b0e87715e232",
   "metadata": {},
   "source": [
    "### 2.Node\n",
    "Nodes are python functions. Each node:\n",
    "\n",
    "- Takes the state as input\n",
    "- Performs some operation\n",
    "- Returns updates to the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82626c92-71c0-4dd2-8e63-31db3a3439db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" I am\"}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" happy!\"}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" sad!\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f41dc9-2b1e-481e-994d-736215d9771e",
   "metadata": {},
   "source": [
    "For example, Nodes can contain:\n",
    "\n",
    "- **LLM calls**: Generate text or make decisions\n",
    "- **Tool calls**: Interact with external systems\n",
    "- **Conditional logic**: Determine next steps\n",
    "- **Human intervention**: Get input from users\n",
    "\n",
    "> 💡 Info: Some nodes necessary for the whole workflow like START and END exist from langGraph directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2ab5b-8d69-479c-80b7-b4253df92cb7",
   "metadata": {},
   "source": [
    "### 3.Edges\n",
    "**Edges** connect nodes and define the possible paths through your graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f42bd38-7e40-4d4f-99da-556e53fc05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "    \n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    user_input = state['graph_state'] \n",
    "    \n",
    "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "    if random.random() < 0.5:\n",
    "\n",
    "        # 50% of the time, we return Node 2\n",
    "        return \"node_2\"\n",
    "    \n",
    "    # 50% of the time, we return Node 3\n",
    "    return \"node_3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4880e5-e774-4928-b25b-19dc4bfed80b",
   "metadata": {},
   "source": [
    "Edges can be:\n",
    "\n",
    "- **Direct**: Always go from node A to node B\n",
    "- **Conditional**: Choose the next node based on the current state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc9c6a-b230-4bbc-8267-53568083f02c",
   "metadata": {},
   "source": [
    "### 4. StateGraph\n",
    "\n",
    "The **StateGraph** is the container that holds your entire agent workflow:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d05cde-8f3f-442f-81eb-92878cefc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f639f-6eae-480b-aa2a-faadab6daf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Which can then be visualized! But most importantly, invoked:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac6414-72d9-4d41-bef7-b111c89e1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "graph.invoke({\"graph_state\" : \"Hi, this is Lance.\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
